{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#White-Noise-Model\" data-toc-modified-id=\"White-Noise-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>White Noise Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Properties\" data-toc-modified-id=\"Properties-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Properties</a></span></li><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Example</a></span></li></ul></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Random Walk Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Properties\" data-toc-modified-id=\"Properties-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Properties</a></span></li><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Example</a></span></li><li><span><a href=\"#Variation:-Random-Walk-w/-a-Drift\" data-toc-modified-id=\"Variation:-Random-Walk-w/-a-Drift-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Variation: Random Walk w/ a Drift</a></span></li></ul></li><li><span><a href=\"#Autoregressive-(AR)-Model\" data-toc-modified-id=\"Autoregressive-(AR)-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Autoregressive (AR) Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Properties\" data-toc-modified-id=\"Properties-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Properties</a></span></li><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Example</a></span></li></ul></li><li><span><a href=\"#Moving-Average-(MA)-Model\" data-toc-modified-id=\"Moving-Average-(MA)-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Moving Average (MA) Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Example</a></span></li></ul></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>ARMA Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Higher-Order\" data-toc-modified-id=\"Higher-Order-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Higher Order</a></span></li><li><span><a href=\"#Choosing-Number-of-Terms\" data-toc-modified-id=\"Choosing-Number-of-Terms-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Choosing Number of Terms</a></span></li><li><span><a href=\"#ARIMA,-SARIMA,-SARIMAX\" data-toc-modified-id=\"ARIMA,-SARIMA,-SARIMAX-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>ARIMA, SARIMA, SARIMAX</a></span></li></ul></li><li><span><a href=\"#Forecasting-a-Time-Series\" data-toc-modified-id=\"Forecasting-a-Time-Series-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Forecasting a Time Series</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train,-Validation,-Test\" data-toc-modified-id=\"Train,-Validation,-Test-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Train, Validation, Test</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fixed-Partitioning\" data-toc-modified-id=\"Fixed-Partitioning-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Fixed Partitioning</a></span></li><li><span><a href=\"#Roll-Forward-Partitioning\" data-toc-modified-id=\"Roll-Forward-Partitioning-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>Roll-Forward Partitioning</a></span></li></ul></li><li><span><a href=\"#The-Baseline-Model---Naive-Forecasting\" data-toc-modified-id=\"The-Baseline-Model---Naive-Forecasting-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>The Baseline Model - Naive Forecasting</a></span></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Exercise</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Time Series Modeling</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Nov 2022\n",
    "<p>Phase 4: Topic 35</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Build simple models like the white noise and random walk models\n",
    "- Explain auto-regressive and moving-average models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# White Noise Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://machinelearningmastery.com/white-noise-time-series-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The **white noise model** is a stationary series where the error term is randomly distributed around the mean, has constant variance, and no autocorrelation.\n",
    "\n",
    "This might not sound very useful at first, but we can use this to build more complex models.\n",
    "\n",
    "Goal after you model is to have white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fixed/constant mean\n",
    "- Fixed/constant variance\n",
    "- No correlation over time (pattern is random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Formula: $Y(t) = \\epsilon(t)$ where $\\epsilon(t+1)$ is a value independent of $\\epsilon(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Note that a *Gaussian white noise* model has mean of 0 and variance of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why is it important?\n",
    "\n",
    "Predictability: If your series is white noise, then by definition, it is random. You can't reasonably model it and make predictions.\n",
    "   \n",
    "Model Diagnostics: The series of errors from a time series forecast model ideally be white noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Is my Time Series white noise?\n",
    "Your time series is probably not white noise if one or more of the following conditions are true:\n",
    "\n",
    "Is the mean non-zero? Does the mean change over time? Does the variance change over time? Do values correlate with lag values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that a *Gaussian white noise* model has mean of 0 and variance of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create a date series\n",
    "n_days = 100\n",
    "date_series = pd.date_range(start='1/1/2015', periods=n_days)\n",
    "date_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a normally distributed temperature values for each day\n",
    "avg_temp = 10\n",
    "std_temp = 3\n",
    "\n",
    "temp_series = np.random.normal(avg_temp, std_temp, n_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Think about pine trees dropping needles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "time_series = pd.Series(data=temp_series, index=date_series)\n",
    "\n",
    "\n",
    "ax = time_series.plot(figsize=(14, 6))\n",
    "ax.set_ylabel(\"Temperature (C)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Walk Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://machinelearningmastery.com/gentle-introduction-random-walk-times-series-forecasting-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Previous value will influence the current value\n",
    "\n",
    "- No specified mean\n",
    "- No specified variance\n",
    "- Strong dependence over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Formula: $Y(t) =Y(t-1) + \\epsilon(t)$\n",
    "\n",
    "$\\epsilon(t)$ is a white noise model with a mean of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "avg = 0\n",
    "std = 10\n",
    "n_pts = 2000\n",
    "\n",
    "# Dates & white noise (epsilon)\n",
    "date_vals = pd.date_range(start='1/1/2015', periods=n_pts)\n",
    "epsilon = np.random.normal(avg, std, n_pts)\n",
    "\n",
    "# Generate data starting at y0 & \"walk\" based on epsilon (white noise model)\n",
    "y0 = 0\n",
    "vals = y0 + np.cumsum(epsilon) \n",
    "time_series = pd.Series(vals, index=date_vals)\n",
    "\n",
    "# Plot out the model\n",
    "ax = time_series.plot(figsize=(14, 6))\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variation: Random Walk w/ a Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\"Drifts\" with a particular value\n",
    "\n",
    "Formula: $Y(t) = c + Y(t-1) + \\epsilon(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Same values from above but have a constant \"drift\" in the epsilon\n",
    "c = .7 \n",
    "#c = -2\n",
    "\n",
    "vals_drift = y0 + np.cumsum(c + epsilon) \n",
    "\n",
    "time_series_drift =  pd.Series(vals_drift, index=date_vals)\n",
    "\n",
    "# Plot out the model\n",
    "ax = time_series.plot(figsize=(14, 6), label='orginal')\n",
    "time_series_drift.plot(label='drifting')\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoregressive (AR) Model  (p term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AR Term\n",
    "\n",
    "- Previous values based on lags\n",
    "- AR(1) - previous day value\n",
    "- AR(2) - yesterday and the day before yesterday\n",
    "- AR(3) - yesterday, the day before yesterday, and the day before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Formula: $Y(t) = \\mu + \\phi * Y(t-1)+\\epsilon(t)$\n",
    "\n",
    "> $\\phi = 0$: simply the white noise model (mean of $\\mu$)\n",
    ">\n",
    "> $\\phi \\lt 0$: oscillates\n",
    ">\n",
    "> $\\phi \\gt 0$: previous points correlate with past (**autocorrelated**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "avg = 0\n",
    "std = 4\n",
    "n_pts = 100\n",
    "\n",
    "\n",
    "mu = 7\n",
    "phi =  0\n",
    "# phi = 0.1\n",
    "# phi = 0.5\n",
    "# phi = 0.9\n",
    "# phi = -0.1\n",
    "# phi = -0.5\n",
    "# phi = -0.9\n",
    "# phi = 3\n",
    "\n",
    "# Dates & white noise (epsilon)\n",
    "date_vals = pd.date_range(start='1/1/2015', periods=n_pts)\n",
    "epsilon = np.random.normal(avg, std, n_pts)\n",
    "\n",
    "#\n",
    "vals = []\n",
    "y = 0\n",
    "for e in epsilon:\n",
    "    y = y * phi + e + mu\n",
    "    vals.append(y)\n",
    "    \n",
    "    \n",
    "time_series =  pd.Series(vals, index=date_vals)\n",
    "\n",
    "# Plot out the model\n",
    "ax = time_series.plot(figsize=(14, 6))\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = pd.plotting.lag_plot(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(time_series);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moving Average (MA) Model (q term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Formula: $Y(t) = \\mu + \\theta * \\epsilon(t-1)+\\epsilon(t)$\n",
    "\n",
    "> $\\theta = 0$: simply the white noise model (mean of $\\mu$)\n",
    ">\n",
    "> $\\theta \\lt 0$: oscillates\n",
    ">\n",
    "> $\\theta \\gt 0$: previous points correlate with past (**autocorrelated**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "avg = 0\n",
    "std = 4\n",
    "n_pts = 100\n",
    "\n",
    "\n",
    "mu = 7\n",
    "theta = 0\n",
    "# theta = 0.1\n",
    "# theta = 0.5\n",
    "# theta = 0.9\n",
    "# theta = -0.1\n",
    "# theta = -0.5\n",
    "# theta = -0.9\n",
    "# theta = 100\n",
    "\n",
    "# Dates & white noise (epsilon)\n",
    "date_vals = pd.date_range(start='1/1/2015', periods=n_pts)\n",
    "epsilon = np.random.normal(avg, std, n_pts+1)\n",
    "\n",
    "#\n",
    "vals = []\n",
    "y = 0\n",
    "for i in range(len(epsilon)-1):\n",
    "    y = epsilon[i] * theta  + epsilon[i+1] + mu\n",
    "    vals.append(y)\n",
    "    \n",
    "    \n",
    "time_series =  pd.Series(vals, index=date_vals)\n",
    "\n",
    "# Plot out the model\n",
    "ax = time_series.plot(figsize=(14, 6))\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ARMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Combine them together; can have both regression on past values (AR) and previous errors affecting future errors (MA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Formula: $Y(t) = \\mu + \\epsilon(t) + \\phi * Y(t-1) +  \\theta * \\epsilon(t-1)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Higher Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ARMA(2,1) yields\n",
    "\n",
    "$Y(t) = \\mu + \\epsilon(t) + \\phi_2 * Y(t-2) + \\phi_1 * Y(t-1) +  \\theta * \\epsilon(t-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing Number of Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many AR or MA terms should our model have?\n",
    "\n",
    "One good way of proceeding is to check the plots of autocorrelations and partial autocorrelations. More on this in the next lesson!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ARIMA, SARIMA, SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In practice, our raw time series data will not be stationary, and the general strategy will be to take differences to try to get a stationary series.\n",
    "\n",
    "If the first-order differences of consecutive terms *themselves* do not form a stationary series, then the typical move is to consider *second-order* differences, i.e. differences of the differences.\n",
    "\n",
    "It would be nice to have a modeling algorithm that would do our differencing for us. That is the point of **ARIMA** models. The 'I' stands for **integrated**, and the `statsmodels` tool will let us specify, in addition to the number of AR and MA terms, also the degree of difference on our raw data series that we want to use.\n",
    "\n",
    "Sometimes we want to have separate AR and MA terms so that we can model time series that have a **seasonal** component. That's what [**SARIMA** modeling](https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/) is all about.\n",
    "\n",
    "In other cases we want to make use also of other predictors, or **exogenous** variables. For those situations we can use build **SARIMAX** models, which would be **S**easonal **A**uto-**R**egressive **I**ntegrated **M**oving-**A**verage models with e**X**ogenous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forecasting a Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Forecasting for a time series will deviate a bit from our prior machine learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train, Validation, Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When developing a time series model, we can't split our data randomly, since the whole point  is to make use of values that are near in time to other values. Typically we'll train on the earlier data points and test on the later ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixed Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> In **fixed partitioning**, we designate sections for training, validation, and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/train-valid-test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It's common to use new _incoming_ data as the test set and only have a training and validation set.\n",
    "\n",
    "![](images/train-valid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After training and evaluating, we will train the _whole_ model on all the data (train, validation, and test sets) since time series typically will rely on past data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Roll-Forward Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> In **roll-forward** partitioning, we evaluate the model on the data following after the training cutoff and incrementally include more data, evaluating on the next set of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/train-valid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The hope is to better simulate what real-world production will look like at the cost of training the model multiple times.\n",
    "\n",
    "For more on validation of time series models see [this helpful blog post](https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Baseline Model - Naive Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> A simple (though sometimes difficult to beat) model is the **naive model** which is just the data shifted by one time-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/naive_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is easily accomplished for Pandas objects with the `.shift()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "time_series.shift(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack((time_series.values.reshape(-1, 1),\n",
    "                       time_series.shift().values.reshape(-1, 1),\n",
    "                       time_series.shift(periods=2).values.reshape(-1, 1))),\n",
    "             columns=['orig', 'shifted_one_period', 'shifted_two_periods'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Plot the two shifted sequences as well as the original on the same axis.\n",
    "2. Using the shifted sequences as model predictions, calculate the RMSE of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer 1</summary>\n",
    "<code>ax = time_series.plot(figsize=(15,10))\n",
    "time_series.shift(1).plot()\n",
    "time_series.shift(2).plot()\n",
    "ax.legend(['Original', 'shift 1', 'shift 2'])\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rms_shift1 = mean_squared_error(df['orig'][1:], df['shifted_one_period'][1:], squared=False)\n",
    "rms_shift2 = mean_squared_error(df['orig'][2:], df['shifted_two_periods'][2:], squared=False)\n",
    "\n",
    "print(rms_shift1)\n",
    "\n",
    "print(rms_shift2)</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer 2</summary>\n",
    "<code>import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize = (25,15))\n",
    "\n",
    "ax.plot(time_series.index, df.iloc[:,0])\n",
    "ax.plot(time_series.index, df.iloc[:,1])\n",
    "ax.plot(time_series.index, df.iloc[:,2])\n",
    "\n",
    "rms_shift1 = np.sqrt(mean_squared_error(df['orig'][1:], df['shifted_one_period'][1:]))\n",
    "rms_shift2 = np.sqrt(mean_squared_error(df['orig'][2:], df['shifted_two_periods'][2:]))\n",
    "    \n",
    "print(rms_shift1)\n",
    "print(rms_shift2)</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer 3</summary>\n",
    "<code>fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(df.index, df['orig'])\n",
    "ax.plot(df.index, df['shifted_one_period'])\n",
    "ax.plot(df.index, df['shifted_two_periods']);\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rms_shift1 = np.sqrt(mean_squared_error(df['orig'][1:], df['shifted_one_period'][1:]))\n",
    "rms_shift2 = np.sqrt(mean_squared_error(df['orig'][2:], df['shifted_two_periods'][2:]))\n",
    "print(rms_shift1)\n",
    "print(rms_shift2)</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dplearn",
   "language": "python",
   "name": "dplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.85px",
    "left": "1386.4px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
