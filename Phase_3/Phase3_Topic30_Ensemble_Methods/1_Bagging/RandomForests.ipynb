{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Ensemble Learning: Bagging and Random Forests\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Nov 2022\n",
    "<p>Phase 3: Topic 30</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier,\\\n",
    "ExtraTreesClassifier, VotingClassifier, StackingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Kim-Jong-un after using decision tree: launch nukes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/kimjongun.jpg\" width = 700 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maybe better to make this a more democratic process with more perspectives on the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Other decision makers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table><tr><td><img src=\"Images/mother_teresa.webp\" width=\"250\"/><br><center>Mother Theresa</center></td><td><img src=\"Images/sakharov.jpg\" width=\"200\"/><br><center>Andrei Sakharov</center></td><td><img src=\"Images/cat_press_button.gif\" width=\"300\"/><br><center>Nice kitty.</center></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This thinking applicable to all models:\n",
    "- particularly useful in the context of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Deficiencies of Decision Trees:\n",
    "- that ensemble learning can address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reminder of decision trees: \n",
    "- recursively make splits based on entropy or impurity (want to go towards 0)\n",
    "- split on feature best increasing information gain\n",
    "- Keep splitting until leaf pure OR max depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dec_tree_partitioning.jpg\" width = 800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Tendency to overfit at large max depth.\n",
    "- High enough depth: will fit to training set perfectly.\n",
    "\n",
    "<img src = \"Images/dectree_perfectfit.png\" />\n",
    "<center> A perfect fit to the training set. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/decisiontree_classification_overfitting.png\"  />\n",
    "<center> Some more decision tree overfitting </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Too much **variance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfiting - the test error separates from the training error ( too much variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To avoid: reduce decision tree depth to limit variance.\n",
    "    \n",
    "But with decision tree, will easily end up underfitting.\n",
    "\n",
    "- Can increase depth again to get better:\n",
    "    - But very likely to learn a boundary that overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dectree_underfitting.png\" width = 400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias-variance problem is severe with Decision Tree models:\n",
    "- Very sensitive to tree depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A very nice visualization of this sensitivity on the regression task:\n",
    "<img src = \"Images/decision_tree_regression.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Decision trees not-robust**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Criterion is harsh: choose *single* feature that wins and split on that.\n",
    "- But many features may be important in a region and should be factored in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"Images/tree_features.png\" />\n",
    "Both Culmen length and depth matter here. But split for each region considers only one or the other.\n",
    "\n",
    "- Doesn't reflect the way features are related to each other and collectively impact the target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Can we figure out a way in a split for a given subregion to factor in different features?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Depending on goal could be nice if modeling target-feature function:\n",
    "- without feature engineering.\n",
    "- without distributional assumptions ( non-parametrics, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another issue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recursion: after split on \"best\" feature, different subsets never talk to each other again.\n",
    "- But maybe other branches/regions: info influencing split/class assignment in given subregion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dec_tree_partitioning.jpg\" width =500/>\n",
    "<center>Choosing next split: black or orange?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Perhaps sampling/factoring in different regions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Increasing depth and number of splits:\n",
    "- Very quickly: small number of points in given sub-region\n",
    "- Feature decision very sensitive to points in specific region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points.png\" width = 200 />\n",
    "<center> Plausible small subregion with few points </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two possible choices (equivalent in terms of impurity):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt1.png\" width = 200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt2.png\" width = 200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Decision boundary instability: \n",
    "- small changes/fluctuations in data lead to very different decision surface locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt1_inst.png\" width =400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt2_inst.png\" width =400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to get around this? How to deal with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Don't want to rely too heavily on specific data points and their location:\n",
    "- Maybe introducing randomness in data point sampling in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Why am I using decision trees at all then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Decision trees are blindingly fast.\n",
    "- Recursion on binary trees\n",
    "- Greedy criterion:\n",
    "    - always split on best feature at local node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Want to keep this speed and still use trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But also want to:\n",
    "- Sample other features when making splits\n",
    "- Sample other regions in feature-space when making decisions on class assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Learn from classifiers training on different realizations of the dataset:\n",
    "    - a set of given points has different weight/importance in each realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Way to create realization of dataset with different weights for data: \n",
    "- **Bagging (boostrap aggregation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src = \"Images/sample_bagging_only.png\" width = 1000/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src = \"Images/sample_bagging_only.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The boostrap:\n",
    "\n",
    "- N samples in training set.\n",
    "- Randomly resample training set **with replacement** N times.\n",
    "- Resampled set also has N samples.\n",
    "\n",
    "A given point now has different weight/importance in each realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More explicitly: see training point reweighting under bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  1. ],\n",
       "       [ 3.1,  0. ],\n",
       "       [-2.5,  1. ],\n",
       "       [ 1. ,  0. ],\n",
       "       [-4. ,  1. ],\n",
       "       [ 0.5,  0. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (feature, label) pairs\n",
    "train = np.array([(-1,1), (3.1, 0) , (-2.5, 1),\n",
    "         (1, 0), (-4, 1), (.5, 0)])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.5,  1. ],\n",
       "       [-4. ,  1. ],\n",
       "       [-2.5,  1. ],\n",
       "       [-1. ,  1. ],\n",
       "       [-4. ,  1. ],\n",
       "       [-2.5,  1. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "idx_resampled =choice(range(len(train)), \n",
    "                      size = len(train),\n",
    "                       replace = True)\n",
    "train[idx_resampled]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Now use ensemble of trained models\n",
    "- Aggregate to make prediction on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/bagging_classifier.png\" width = 900/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the context of regression:\n",
    "- aggregation function is average of regressor trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/bagging_regressor.png\"width = 900 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The concept of bagging of estimators is **NOT** limited to trees:\n",
    "- can use any classifier or regressor and perform bagging procedures.\n",
    "- but mainly useful for local models like DecisionTree or KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To implement bagging classifier in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# if doing classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# if doing regression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll do classification:\n",
    "- Predict diabetes via health stats\n",
    "- Pima Indian diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df = pd.read_csv('Data/diabetes.csv')\n",
    "diab_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "diab_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df.head()\n",
    "# different scales, but for decision trees we don't have to standardise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Separate features and target\n",
    "- Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = diab_df.drop(columns = ['Outcome'])\n",
    "y = diab_df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now develop our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define the bagging classifier and put it into a pipeline. \n",
    "\n",
    "Then integrate into a grid search tuning on tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# baggingclassifier wrapper function - tell which model you are using, baging a 150 trees\n",
    "bag_class_decision = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 150)\n",
    "# no need for standardizing, it can be emited\n",
    "bag_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       bag_class_decision)])\n",
    "params = {'model__base_estimator__max_depth': np.arange(4,28,4)} # tuning the max_depth of the decisiontreelassifier\n",
    "# two undersore after model, to get to the base estimator, the base estimator is a hyperparameter \n",
    "cv = GridSearchCV(estimator = bag_pipe, param_grid = params, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Get best model and its balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__base_estimator__max_depth': 16}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get/save the best model\n",
    "best_model = cv.best_estimator_\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529770992366412"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__base_estimator__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.751403</td>\n",
       "      <td>0.040056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.751368</td>\n",
       "      <td>0.053763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.745261</td>\n",
       "      <td>0.046099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.752977</td>\n",
       "      <td>0.036091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.040606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>0.746788</td>\n",
       "      <td>0.046282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_model__base_estimator__max_depth  mean_test_score  std_test_score\n",
       "0                                      4         0.751403        0.040056\n",
       "1                                      8         0.751368        0.053763\n",
       "2                                     12         0.745261        0.046099\n",
       "3                                     16         0.752977        0.036091\n",
       "4                                     20         0.746835        0.040606\n",
       "5                                     24         0.746788        0.046282"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.cv_results_)[['param_model__base_estimator__max_depth', 'mean_test_score', 'std_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fit the best model. Get predictions and report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        76\n",
      "           1       0.65      0.65      0.65        40\n",
      "\n",
      "    accuracy                           0.76       116\n",
      "   macro avg       0.73      0.73      0.73       116\n",
      "weighted avg       0.76      0.76      0.76       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# precision scores are not so great so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Is bagging better than baseline decision tree over the same range of tree depths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "simpletree_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       DecisionTreeClassifier())]) \n",
    "\n",
    "params = {'model__max_depth': np.arange(4,28,4)}\n",
    "\n",
    "cvtree = GridSearchCV(estimator = simpletree_pipe, param_grid = params, cv = 5)\n",
    "\n",
    "cvtree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_simplemodel = cvtree.best_estimator_\n",
    "cvtree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7237815619495009"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvtree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        76\n",
      "           1       0.62      0.57      0.60        40\n",
      "\n",
      "    accuracy                           0.73       116\n",
      "   macro avg       0.70      0.70      0.70       116\n",
      "weighted avg       0.73      0.73      0.73       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_simplemodel.fit(X_train, y_train)\n",
    "y_pred_simple = best_simplemodel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A bit worse on the precision/recall for all classes -- especially positive class. \n",
    "- In many cases improvements on bagging alone will not be so significant.\n",
    "- Sample bagging alone usually not enough to capture feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reason: \n",
    "- boostrapped samples are still highly correlated with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Final ingredient (first set of strategies)\n",
    "\n",
    "- Effectively factor in other features when making splits\n",
    "- Sample other regions in feature-space when making decisions on class assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can effectively do this by considering only a random subset of features to split on at each node\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Result: each tree may partition feature space in appreciably different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"Images/rf_splitting.png\"  width = 900/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Overall effect of this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/indtree.gif\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each decision tree can learn different important features to make splits on throughout feature space.\n",
    "- Each tree can assign a given feature region to different classes based on its splits.\n",
    "\n",
    "Individual trees making errors but **different** errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"Images/rfplot.gif\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Aggregating smooths large fluctuations of class assignments from individual trees out.\n",
    "- Due to feature subset sampling: can learn more complex boundaries: smoothens these.\n",
    "- Can also get probability of class assignment.\n",
    "- white is the boundary line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's try out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       RandomForestClassifier(n_estimators = 100, random_state= 42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_rf_pred = rf_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82        76\n",
      "           1       0.68      0.57      0.62        40\n",
      "\n",
      "    accuracy                           0.76       116\n",
      "   macro avg       0.73      0.72      0.72       116\n",
      "weighted avg       0.75      0.76      0.75       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Better than bagging and base Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Should tune model: understand relevant hyperparameters\n",
    "- understand parameters of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- n_estimators: number of trees in forest (very important):\n",
    "    - optimal will depend on dataset size. But 50-250 is good starting tuning range.\n",
    "- max_features: number of features to randomly sample at each node for evaluating split criterion.\n",
    "    - good starting value (also default) is $\\sqrt{M}$ where $M$ is number of features. (theoretical justification for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- max_depth: tree depth\n",
    "    - due to randomizing and averaging: random forest not as sensitive to this as DecisionTree.\n",
    "    - default is None. Trains tree to leaf purity. Typically don't touch this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- min_sample_leaf: minimum number of samples required to be at a leaf node.\n",
    "    - Default is 1 but having larger numbers can mean averaging effect from leaf\n",
    "    - Higher values can have a regularizing effect.\n",
    "    - Typically tune from 1-100 (depends on size of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For min sample leaf criterion: cuts out different portions of tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/min_sample_leaf.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can also change objective functions:\n",
    "- Gini\n",
    "- entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Grid Search CV on our random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('model',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'model__min_samples_leaf': [1, 3, 5, 7],\n",
       "                         'model__n_estimators': [50, 100, 200, 500]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {'model__n_estimators': [50, 100, 200, 500] ,\n",
    "             'model__min_samples_leaf': [1,3,5,7]}\n",
    "rf_cv = GridSearchCV(estimator = rf_pipe, param_grid = rf_params, cv = 5)\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759953024075161"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__min_samples_leaf': 3, 'model__n_estimators': 50}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(min_samples_leaf=3, n_estimators=50,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model = rf_cv.best_estimator_\n",
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(min_samples_leaf=3, n_estimators=50,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84        76\n",
      "           1       0.71      0.60      0.65        40\n",
      "\n",
      "    accuracy                           0.78       116\n",
      "   macro avg       0.76      0.73      0.74       116\n",
      "weighted avg       0.77      0.78      0.77       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_rfcv_pred = best_rf_model.predict(X_test)\n",
    "print(classification_report(y_test,y_rfcv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK this is pretty decent. There is also another nice thing about random forests:\n",
    "\n",
    "Can see which features are most important in prediction:\n",
    "\n",
    "- .feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp = best_rf_model['model'].feature_importances_\n",
    "\n",
    "feat_imp_series = pd.Series(feat_imp, \n",
    "          index = X.columns).sort_values(\n",
    "    ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose                     0.276591\n",
       "BMI                         0.185480\n",
       "Age                         0.127925\n",
       "DiabetesPedigreeFunction    0.114975\n",
       "Pregnancies                 0.082138\n",
       "BloodPressure               0.079951\n",
       "SkinThickness               0.067124\n",
       "Insulin                     0.065816\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_series\n",
    "# glucose is the most important when it comes to classification, it says 27% of the time glucose was used in the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp_series.plot(kind = 'barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluates feature importance:\n",
    "- Determining for each tree how many times feature was used for splitting.\n",
    "- Counts up occurences across entire forest and weights features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Extremely Randomized Trees (Extra Trees)\n",
    "- Sometimes our variance problems are extreme.\n",
    "- Random forest taking way too long with too many estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Might want even one more randomization. \n",
    "- Instead of always choosing the *optimal* split at node:\n",
    "    - randomly sample feature space inside node. \n",
    "    - split on best information gain from random sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now **three** levels of randomization: \n",
    "- sampling of data\n",
    "- sampling of features\n",
    "- random selection of branching paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's import it and do our magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(max_features='sqrt',\n",
    "                         max_samples=0.5,\n",
    "                         bootstrap=True,\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, max_features='sqrt', max_samples=0.5,\n",
       "                     random_state=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it\n",
    "etc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82442748, 0.77862595, 0.76153846, 0.73846154, 0.72307692])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation\n",
    "scores = cross_val_score(estimator=etc, X=X_train, y=y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7615384615384615"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7758620689655172"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score on test\n",
    "etc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84        76\n",
      "           1       0.71      0.60      0.65        40\n",
      "\n",
      "    accuracy                           0.78       116\n",
      "   macro avg       0.76      0.73      0.74       116\n",
      "weighted avg       0.77      0.78      0.77       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_etc_pred = etc.predict(X_test)\n",
    "print(classification_report(y_test, y_etc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sometimes** the extra randomization can do even better.\n",
    "- When suffering from variance issues.\n",
    "- Also ExtraTrees is very very fast:\n",
    "    - doesn't spend too much time on finding optimal splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Up: Stacking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta-Classifier/Meta-Regressor\n",
    "\n",
    "- First, we ask several different models to make predictions about the target\n",
    "- Rather than taking a simple average or vote to determine the outcome, feed these results into a final model that makes the prediction based on the other models predictions\n",
    "- If it seems like we are approaching a neural network...you are correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember weighted averaging? Stacking is about using DS models to estimate those weights for us. This means we'll have one layer of base estimators and another layer that is \"**trained to optimally combine the model predictions to form a new set of predictions**\". See [this short blog post](https://blogs.sas.com/content/subconsciousmusings/2017/05/18/stacked-ensemble-models-win-data-science-competitions/) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = xlrd.open_workbook('data/Sales Report.xls',\n",
    "                        logfile=open(os.devnull, 'w'))\n",
    "\n",
    "sales = pd.read_excel(wb)\n",
    "sales = sales.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2017-138688</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036.0</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2017-152156 2017-11-08 2017-11-11    Second Class    CG-12520   \n",
       "1       2  CA-2017-152156 2017-11-08 2017-11-11    Second Class    CG-12520   \n",
       "2       3  CA-2017-138688 2017-06-12 2017-06-16    Second Class    DV-13045   \n",
       "3       4  US-2016-108966 2016-10-11 2016-10-18  Standard Class    SO-20335   \n",
       "4       5  US-2016-108966 2016-10-11 2016-10-18  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City  ...  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0     42420.0   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1     42420.0   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2     90036.0    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3     33311.0   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4     33311.0   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row ID                    int64\n",
       "Order ID                 object\n",
       "Order Date       datetime64[ns]\n",
       "Ship Date        datetime64[ns]\n",
       "Ship Mode                object\n",
       "Customer ID              object\n",
       "Customer Name            object\n",
       "Segment                  object\n",
       "Country                  object\n",
       "City                     object\n",
       "State                    object\n",
       "Postal Code             float64\n",
       "Region                   object\n",
       "Product ID               object\n",
       "Category                 object\n",
       "Sub-Category             object\n",
       "Product Name             object\n",
       "Sales                   float64\n",
       "Quantity                  int64\n",
       "Discount                float64\n",
       "Profit                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Office Supplies    6020\n",
       "Furniture          2119\n",
       "Technology         1844\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binders        1523\n",
       "Paper          1368\n",
       "Furnishings     957\n",
       "Phones          888\n",
       "Storage         845\n",
       "Art             795\n",
       "Accessories     773\n",
       "Chairs          616\n",
       "Appliances      465\n",
       "Labels          364\n",
       "Tables          319\n",
       "Envelopes       253\n",
       "Bookcases       227\n",
       "Fasteners       217\n",
       "Supplies        190\n",
       "Machines        115\n",
       "Copiers          68\n",
       "Name: Sub-Category, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Sub-Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the num er and categorical columns\n",
    "X_num = sales[['Discount', 'Profit']].columns\n",
    "X_cat = sales[['Category', 'Sub-Category']].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "X = sales[['Discount', 'Profit',\n",
    "          'Category', 'Sub-Category']]\n",
    "y = sales['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrans = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "catTrans = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(drop='first',\n",
    "                          sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = ColumnTransformer(transformers=[\n",
    "    ('num', numTrans, X_num),\n",
    "    ('cat', catTrans, X_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_pp = pp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pp = pp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', LinearRegression()),\n",
    "    ('knn', KNeighborsRegressor()),\n",
    "    ('rt', DecisionTreeRegressor())\n",
    "]\n",
    "# linear regression makes predictions and next if fed into kneighbors and those predictions are fed into decisiontree\n",
    "sr = StackingRegressor(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_p = Pipeline([('preprocess', pp), ('model', sr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['Discount', 'Profit'], dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['Category', 'Sub-Category'], dtype='object'))])),\n",
       "                ('model',\n",
       "                 StackingRegressor(estimators=[('lr', LinearRegression()),\n",
       "                                               ('knn', KNeighborsRegressor()),\n",
       "                                               ('rt',\n",
       "                                                DecisionTreeRegressor())]))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161003083990739"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_p.score(X_test, y_test)\n",
    "#stacking gives better resutl , 0.81, use it was one\n",
    "# one model use stacking\n",
    "# the next one: take all the results and average it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Base Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42942244281549513"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_tr_pp, y_train)\n",
    "lr.score(X_test_pp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7958897976080597"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor().fit(X_tr_pp, y_train)\n",
    "knn.score(X_test_pp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24762856564092406"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = DecisionTreeRegressor().fit(X_tr_pp, y_train)\n",
    "rt.score(X_test_pp, y_test)\n",
    "# overfiting, score 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
